{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import cross_validate,StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "import os\n",
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_data,test_target,classifier):\n",
    "    correct=0\n",
    "    conf_mat = confusion_matrix(test_target,classifier.predict(test_data))\n",
    "    for i in range(len(conf_mat)):\n",
    "        correct += conf_mat[i][i]\n",
    "    return correct/len(test_data),conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "experimentation = RUN in Notebook gives LDA and PCA\n",
    "model = Display accuracy for the best model\n",
    "'''\n",
    "mode = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "train_data = np.append(training_data[0],validation_data[0],axis=0)\n",
    "train_target = np.append(training_data[1],validation_data[1])\n",
    "test_target = test_data[1]\n",
    "test_data = test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(mode == 'experimentation'):\n",
    "    scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "    processed_train_data = scaler.fit_transform(train_data)\n",
    "    processed_test_data = scaler.fit_transform(test_data)\n",
    "\n",
    "    pca = PCA().fit(train_data)\n",
    "    lda = LinearDiscriminantAnalysis().fit(processed_train_data,train_target)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(np.cumsum(lda.explained_variance_ratio_))\n",
    "    plt.xlabel('Number of Components for LDA')\n",
    "    plt.ylabel('Variance (%)') #for each component\n",
    "    plt.title('Variance')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('Number of Components for PCA')\n",
    "    plt.ylabel('Variance (%)') #for each component\n",
    "    plt.title('Variance')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    pca = PCA(n_components=500)\n",
    "    pca_processed_train_data = pca.fit_transform(train_data)\n",
    "    pca_processed_test_data = pca.fit_transform(test_data)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=8)\n",
    "    lda_processed_train_data = lda.fit(train_data, train_target).transform(train_data)\n",
    "    lda_processed_test_data = lda.transform(test_data)\n",
    "\n",
    "    # Set the parameters by cross-validation\n",
    "    # Ref https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2,1e-3,1e-4],'C': [1,2,3,4,5]},\n",
    "                        {'kernel': ['linear'],'gamma': [1e-1,1e-2,1e-3,1e-4], 'C': [1,2,3,4,5]},\n",
    "                        {'kernel': ['poly'],'gamma': [1e-1,1e-2,1e-3,1e-4],'C': [1,2,3,4,5]},\n",
    "                        {'kernel': ['sigmoid'],'gamma': [1e-1,1e-2,1e-3,1e-4],'C': [1,2,3,4,5]}]\n",
    "    scores = ['precision', 'recall']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(SVC(verbose=True,cache_size=7000), tuned_parameters, cv=3,\n",
    "                           scoring='%s_macro' % score)\n",
    "        clf.fit(lda_processed_train_data, train_target)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = test_target, clf.predict(lda_processed_test_data)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "\n",
    "    #joblib.dump(clf,'./models/svmGridSearch.joblib')\n",
    "    clf = joblib.load(\"models/svmGridSearch.joblib\")\n",
    "\n",
    "    clf.best_params_\n",
    "\n",
    "    clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=7024, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = SVC(kernel='linear',cache_size=7024,verbose=True,probability=True)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=7000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline2 = SVC(kernel='rbf', gamma =1,cache_size=7000,verbose=True,probability=True)\n",
    "baseline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=7000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline3 = SVC(kernel='rbf',cache_size=7000,verbose=True,probability=True)\n",
    "baseline3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4= SVC(kernel='rbf', C=2,gamma = 0.05,cache_size=7000,verbose=True,probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=7000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = model4\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "classifier.fit(train_data,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9403, array([[ 957,    0,    4,    1,    1,    6,    9,    1,    0,    1],\n",
       "        [   0, 1122,    3,    2,    0,    1,    2,    1,    4,    0],\n",
       "        [   8,    6,  967,   11,    3,    3,    7,    8,   17,    2],\n",
       "        [   4,    3,   16,  947,    1,   15,    0,    9,   13,    2],\n",
       "        [   1,    1,   10,    1,  942,    2,    4,    2,    3,   16],\n",
       "        [  10,    4,    3,   36,    6,  803,   13,    1,   14,    2],\n",
       "        [   9,    2,   13,    1,    6,   16,  909,    1,    1,    0],\n",
       "        [   1,    8,   21,   10,    8,    1,    0,  957,    3,   19],\n",
       "        [   8,    4,    6,   25,    7,   26,    6,    7,  877,    8],\n",
       "        [   7,    7,    2,   11,   33,    4,    0,   18,    5,  922]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline\n",
    "accuracy(test_data,test_target,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = '../USPSdata/Numerals'\n",
    "savedImg = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-np.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_USPS_test_data = lda.transform(USPSMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29236461823091153,\n",
       " array([[ 368,    0,  503,  149,  161,  345,   67,  200,    9,  198],\n",
       "        [  39,  300,  534,  214,  242,  212,   25,  371,   41,   22],\n",
       "        [ 113,   62, 1288,   97,   35,  263,   67,   42,   21,   11],\n",
       "        [  47,   60,  346,  832,   13,  610,    6,   48,   25,   13],\n",
       "        [  21,   19,  242,   81,  769,  231,   16,  475,   74,   72],\n",
       "        [  34,   13,  656,  215,   30,  949,   24,   35,   30,   14],\n",
       "        [ 143,   17,  857,   50,   64,  341,  455,   32,    1,   40],\n",
       "        [  26,   74,  220,  623,   37,  304,   11,  583,   95,   27],\n",
       "        [ 110,   10,  344,  434,   84,  708,   68,   60,  152,   30],\n",
       "        [  11,   34,  218,  576,  130,  115,    5,  617,  143,  151]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "accuracy(USPSMat,USPSTar,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(USPSMat,USPSTar,classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
