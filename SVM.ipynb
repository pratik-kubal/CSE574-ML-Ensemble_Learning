{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import cross_validate,StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "import os\n",
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_data,test_target,classifier):\n",
    "    correct=0\n",
    "    conf_mat = confusion_matrix(test_target,classifier.predict(test_data))\n",
    "    for i in range(len(conf_mat)):\n",
    "        correct += conf_mat[i][i]\n",
    "    return correct/len(test_data),conf_mat\n",
    "\n",
    "def more_metrics(conf_mat):\n",
    "    true_positives = 0\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for i in range(len(conf_mat)):\n",
    "        true_positives += conf_mat.iloc[i,i]\n",
    "    conf_mat = np.matrix(conf_mat)\n",
    "    tp_fp = np.array(np.sum(conf_mat,axis=1)).ravel()\n",
    "    relevant_elements = np.array(np.sum(conf_mat,axis=0)).ravel()\n",
    "    for i in range(len(conf_mat)):\n",
    "        precision.append(conf_mat[i,i]/tp_fp[i])\n",
    "        recall.append(conf_mat[i,i]/relevant_elements[i])\n",
    "    return true_positives,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "experimentation = RUN in Notebook gives LDA and PCA\n",
    "model = Display accuracy for the best model\n",
    "'''\n",
    "mode = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "train_data = np.append(training_data[0],validation_data[0],axis=0)\n",
    "train_target = np.append(training_data[1],validation_data[1])\n",
    "test_target = test_data[1]\n",
    "test_data = test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(mode == 'experimentation'):\n",
    "    scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "    processed_train_data = scaler.fit_transform(train_data)\n",
    "    processed_test_data = scaler.fit_transform(test_data)\n",
    "\n",
    "    pca = PCA().fit(train_data)\n",
    "    lda = LinearDiscriminantAnalysis().fit(processed_train_data,train_target)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(np.cumsum(lda.explained_variance_ratio_))\n",
    "    plt.xlabel('Number of Components for LDA')\n",
    "    plt.ylabel('Variance (%)') #for each component\n",
    "    plt.title('Variance')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('Number of Components for PCA')\n",
    "    plt.ylabel('Variance (%)') #for each component\n",
    "    plt.title('Variance')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    pca = PCA(n_components=500)\n",
    "    pca_processed_train_data = pca.fit_transform(train_data)\n",
    "    pca_processed_test_data = pca.fit_transform(test_data)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=8)\n",
    "    lda_processed_train_data = lda.fit(train_data, train_target).transform(train_data)\n",
    "    lda_processed_test_data = lda.transform(test_data)\n",
    "\n",
    "    # Set the parameters by cross-validation\n",
    "    # Ref https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2,1e-3,1e-4],'C': [1,2,3,4,5]},\n",
    "                        {'kernel': ['linear'],'gamma': [1e-1,1e-2,1e-3,1e-4], 'C': [1,2,3,4,5]},\n",
    "                        {'kernel': ['poly'],'gamma': [1e-1,1e-2,1e-3,1e-4],'C': [1,2,3,4,5]},\n",
    "                        {'kernel': ['sigmoid'],'gamma': [1e-1,1e-2,1e-3,1e-4],'C': [1,2,3,4,5]}]\n",
    "    scores = ['precision', 'recall']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(SVC(verbose=True,cache_size=7000), tuned_parameters, cv=3,\n",
    "                           scoring='%s_macro' % score)\n",
    "        clf.fit(lda_processed_train_data, train_target)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = test_target, clf.predict(lda_processed_test_data)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "\n",
    "    #joblib.dump(clf,'./models/svmGridSearch.joblib')\n",
    "    clf = joblib.load(\"models/svmGridSearch.joblib\")\n",
    "\n",
    "    clf.best_params_\n",
    "\n",
    "    clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=7024, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = SVC(kernel='linear',cache_size=7024,verbose=True,probability=True)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=7000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline2 = SVC(kernel='rbf', gamma =1,cache_size=7000,verbose=True,probability=True)\n",
    "baseline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=7000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline3 = SVC(kernel='rbf',cache_size=7000,verbose=True,probability=True)\n",
    "baseline3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4= SVC(kernel='rbf', C=2,gamma = 0.05,cache_size=7000,verbose=True,probability=True)\n",
    "model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator SVC from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=7000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier.fit(train_data,train_target)\n",
    "#model5 = joblib.load(\"./models/SVMSlideModel.joblib\")\n",
    "#model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=7024, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model6 = joblib.load(\"./models/SVMpdfModel2.joblib\")\n",
    "#model6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=7000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7 = joblib.load(\"./models/SVMpdfModel3.joblib\")\n",
    "model7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=7000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=2000, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model8= SVC(kernel='rbf', C=2,cache_size=7000, max_iter=2000,verbose=True,probability=True)\n",
    "#model8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=7000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = model7\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Testing on MNIST is: 0.9435\n",
      "The Confusion Matrix is: \n",
      "[[ 967    0    1    0    0    5    4    1    2    0]\n",
      " [   0 1120    2    3    0    1    3    1    5    0]\n",
      " [   9    1  962    7   10    1   13   11   16    2]\n",
      " [   1    1   14  950    1   17    1   10   11    4]\n",
      " [   1    1    7    0  937    0    7    2    2   25]\n",
      " [   7    4    5   33    7  808   11    2   10    5]\n",
      " [  10    3    4    1    5   10  924    0    1    0]\n",
      " [   2   13   22    5    7    1    0  954    4   20]\n",
      " [   4    6    6   14    8   24   10    8  891    3]\n",
      " [  10    6    0   12   33    5    1   14    6  922]]\n",
      "The Precision & Recall is: \n",
      "      Recall  Precision\n",
      "0  98.673469  95.647873\n",
      "1  98.678414  96.969697\n",
      "2  93.217054  94.037146\n",
      "3  94.059406  92.682927\n",
      "4  95.417515  92.956349\n",
      "5  90.582960  92.660550\n",
      "6  96.450939  94.866530\n",
      "7  92.801556  95.114656\n",
      "8  91.478439  93.987342\n",
      "9  91.377602  93.985729\n"
     ]
    }
   ],
   "source": [
    "#model6\n",
    "acc,conf_mat = accuracy(test_data,test_target,classifier)\n",
    "print(\"The Accuracy for Testing on MNIST is: \"+str(acc))\n",
    "print(\"The Confusion Matrix is: \")\n",
    "print(conf_mat)\n",
    "_,precision,recall = more_metrics(pd.DataFrame(conf_mat))\n",
    "print(\"The Precision & Recall is: \")\n",
    "df = pd.DataFrame(np.multiply(precision,100))\n",
    "df.columns = [\"Recall\"]\n",
    "df1 = pd.DataFrame(np.multiply(recall,100))\n",
    "df1.columns = [\"Precision\"]\n",
    "print(pd.concat([df,df1],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = '../USPSdata/Numerals'\n",
    "savedImg = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-np.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Testing on MNIST is: 0.38541927096354817\n",
      "The Confusion Matrix is: \n",
      "[[ 573    2  428   19  285  248   73   44    6  322]\n",
      " [ 110  429  285  137  273  180   46  501   22   17]\n",
      " [ 128   18 1402   59   39  198   61   57   23   14]\n",
      " [  76    3  186 1123   11  483    5   70   27   16]\n",
      " [  18   67   91   14 1167  267   22  194   69   91]\n",
      " [ 108   17  257  102   25 1367   60   43   15    6]\n",
      " [ 197    7  489   24   98  394  748   13    7   23]\n",
      " [  50  225  457  265   57  416   15  452   41   22]\n",
      " [  73   25  209  193   87 1006   95   41  244   27]\n",
      " [  26  166  228  278  213  165    8  499  214  203]]\n",
      "The Precision & Recall is: \n",
      "      Recall  Precision\n",
      "0  28.650000  42.163355\n",
      "1  21.450000  44.734098\n",
      "2  70.135068  34.771825\n",
      "3  56.150000  50.722674\n",
      "4  58.350000  51.751663\n",
      "5  68.350000  28.937341\n",
      "6  37.400000  66.019417\n",
      "7  22.600000  23.615465\n",
      "8  12.200000  36.526946\n",
      "9  10.150000  27.395412\n"
     ]
    }
   ],
   "source": [
    "acc,conf_mat = accuracy(USPSMat,USPSTar,classifier)\n",
    "print(\"The Accuracy for Testing on MNIST is: \"+str(acc))\n",
    "print(\"The Confusion Matrix is: \")\n",
    "print(conf_mat)\n",
    "_,precision,recall = more_metrics(pd.DataFrame(conf_mat))\n",
    "print(\"The Precision & Recall is: \")\n",
    "df = pd.DataFrame(np.multiply(precision,100))\n",
    "df.columns = [\"Recall\"]\n",
    "df1 = pd.DataFrame(np.multiply(recall,100))\n",
    "df1.columns = [\"Precision\"]\n",
    "print(pd.concat([df,df1],axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
