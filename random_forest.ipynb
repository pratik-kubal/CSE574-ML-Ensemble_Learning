{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import cross_validate,StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_data,test_target,classifier):\n",
    "    correct=0\n",
    "    conf_mat = confusion_matrix(test_target,classifier.predict(test_data))\n",
    "    for i in range(len(conf_mat)):\n",
    "        correct += conf_mat[i][i]\n",
    "    return correct/len(test_data),conf_mat\n",
    "\n",
    "def more_metrics(conf_mat):\n",
    "    true_positives = 0\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for i in range(len(conf_mat)):\n",
    "        true_positives += conf_mat.iloc[i,i]\n",
    "    conf_mat = np.matrix(conf_mat)\n",
    "    tp_fp = np.array(np.sum(conf_mat,axis=1)).ravel()\n",
    "    relevant_elements = np.array(np.sum(conf_mat,axis=0)).ravel()\n",
    "    for i in range(len(conf_mat)):\n",
    "        precision.append(conf_mat[i,i]/tp_fp[i])\n",
    "        recall.append(conf_mat[i,i]/relevant_elements[i])\n",
    "    return true_positives,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "train_data = training_data[0]\n",
    "train_target = training_data[1]\n",
    "val_data = validation_data[0]\n",
    "val_target = validation_data[1]\n",
    "test_target = test_data[1]\n",
    "test_data = test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "processed_train_data = scaler.transform(train_data)\n",
    "scaler.fit(val_data)\n",
    "processed_val_data = scaler.transform(val_data)\n",
    "scaler.fit(test_data)\n",
    "processed_test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=True,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseClassifier = RandomForestClassifier(n_estimators=100)\n",
    "baseClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1500, n_jobs=4,\n",
       "            oob_score=False, random_state=None, verbose=True,\n",
       "            warm_start=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highVarClassifier = RandomForestClassifier(n_estimators=1500)\n",
    "highVarClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2500, n_jobs=6,\n",
       "            oob_score=False, random_state=None, verbose=True,\n",
       "            warm_start=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib.dump(superhighVarClassifier,'./models/randomForestModel.joblib')\n",
    "#joblib.load('./models/randomForestModel.joblib') \n",
    "# Warning: Working with 8 cores, if you use around <6 then decrease n_jobs \n",
    "superhighVarClassifier = RandomForestClassifier(n_estimators=2500)\n",
    "superhighVarClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supersuperhighVarClassifier = RandomForestClassifier(n_estimators=3000,n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = joblib.load('./models/randomForestModel.joblib') \n",
    "#classifier.fit(processed_train_data, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Models on different HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Validation is: 0.9892\n",
      "The Confusion Matrix is: \n",
      "     0     1    2     3    4    5    6     7    8    9\n",
      "0  987     0    0     0    1    0    3     0    0    0\n",
      "1    0  1062    1     0    0    0    0     1    0    0\n",
      "2    1     0  987     0    0    0    0     1    1    0\n",
      "3    0     0    3  1020    0    3    0     2    1    1\n",
      "4    0     6    0     0  973    0    0     2    0    2\n",
      "5    0     0    1     1    1  908    4     0    0    0\n",
      "6    2     0    0     0    0    2  963     0    0    0\n",
      "7    0     4    2     0    1    0    0  1082    0    1\n",
      "8    2     8    2     4    0    7    0     2  981    3\n",
      "9    2     1    0     5   11    4    0     9    0  929\n",
      "The Precision & Recall is: \n",
      "      Recall  Precision\n",
      "0  99.596367  99.295775\n",
      "1  99.812030  98.242368\n",
      "2  99.696970  99.096386\n",
      "3  99.029126  99.029126\n",
      "4  98.982706  98.581560\n",
      "5  99.234973  98.268398\n",
      "6  99.586350  99.278351\n",
      "7  99.266055  98.453139\n",
      "8  97.224975  99.796541\n",
      "9  96.670135  99.252137\n"
     ]
    }
   ],
   "source": [
    "acc,conf_mat = accuracy(processed_val_data,val_target,classifier)\n",
    "print(\"The Accuracy for Validation is: \"+str(acc))\n",
    "print(\"The Confusion Matrix is: \")\n",
    "print(pd.DataFrame(conf_mat))\n",
    "_,precision,recall = more_metrics(pd.DataFrame(conf_mat))\n",
    "print(\"The Precision & Recall is: \")\n",
    "df = pd.DataFrame(np.multiply(precision,100))\n",
    "df.columns = [\"Recall\"]\n",
    "df1 = pd.DataFrame(np.multiply(recall,100))\n",
    "df1.columns = [\"Precision\"]\n",
    "print(pd.concat([df,df1],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Process USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = '../USPSdata/Numerals'\n",
    "savedImg = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-np.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(USPSMat)\n",
    "processed_USPSDat = scaler.transform(USPSMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Testing on MNIST is: 0.9668\n",
      "The Confusion Matrix is: \n",
      "[[ 965    1    1    0    0    4    8    1    0    0]\n",
      " [   0 1127    2    1    0    2    2    1    0    0]\n",
      " [   8    1  997    5    2    2    2   13    2    0]\n",
      " [   0    0    6  985    0    4    0   12    2    1]\n",
      " [   1    0    2    0  960    1    6    4    1    7]\n",
      " [   2    1    0    9    0  873    3    2    2    0]\n",
      " [   9    4    1    0    4    3  937    0    0    0]\n",
      " [   0    8   16    0    0    0    0 1001    0    3]\n",
      " [   4    1    7   17    9   23    3    8  893    9]\n",
      " [   8    7    1   12   30    7    1   10    3  930]]\n",
      "The Precision & Recall is: \n",
      "      Recall  Precision\n",
      "0  98.469388  96.790371\n",
      "1  99.295154  98.000000\n",
      "2  96.608527  96.515005\n",
      "3  97.524752  95.724004\n",
      "4  97.759674  95.522388\n",
      "5  97.869955  94.994559\n",
      "6  97.807933  97.401247\n",
      "7  97.373541  95.152091\n",
      "8  91.683778  98.892580\n",
      "9  92.170466  97.894737\n"
     ]
    }
   ],
   "source": [
    "acc,conf_mat = accuracy(processed_test_data,test_target,classifier)\n",
    "print(\"The Accuracy for Testing on MNIST is: \"+str(acc))\n",
    "print(\"The Confusion Matrix is: \")\n",
    "print(conf_mat)\n",
    "_,precision,recall = more_metrics(pd.DataFrame(conf_mat))\n",
    "print(\"The Precision & Recall is: \")\n",
    "df = pd.DataFrame(np.multiply(precision,100))\n",
    "df.columns = [\"Recall\"]\n",
    "df1 = pd.DataFrame(np.multiply(recall,100))\n",
    "df1.columns = [\"Precision\"]\n",
    "print(pd.concat([df,df1],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Testing on USPS is: 0.4097704885244262\n",
      "The Confusion Matrix is: \n",
      "[[ 650   11  267   52  450  169   62   85    2  252]\n",
      " [  44  552  117   99   49  106   28  990   14    1]\n",
      " [  97   24 1271   66   49  209   17  259    5    2]\n",
      " [  37    5   88 1303   53  314    3  177    4   16]\n",
      " [  12  192   53   22 1095  185   15  385   23   18]\n",
      " [ 140   23  132   54   19 1501   22  101    5    3]\n",
      " [ 292   42  206   18   80  364  856  130    2   10]\n",
      " [  36  320  364  230   39  270   28  698    5   10]\n",
      " [  35   40  142  193  101 1163   57   93  166   10]\n",
      " [  15  254  217  304  246  133    8  629   91  103]]\n",
      "The Precision & Recall is: \n",
      "      Recall  Precision\n",
      "0  32.500000  47.864507\n",
      "1  27.600000  37.730690\n",
      "2  63.581791  44.487224\n",
      "3  65.150000  55.659974\n",
      "4  54.750000  50.206327\n",
      "5  75.050000  34.005437\n",
      "6  42.800000  78.102190\n",
      "7  34.900000  19.678602\n",
      "8   8.300000  52.365931\n",
      "9   5.150000  24.235294\n"
     ]
    }
   ],
   "source": [
    "acc,conf_mat = accuracy(processed_USPSDat,USPSTar,classifier)\n",
    "print(\"The Accuracy for Testing on USPS is: \"+str(acc))\n",
    "print(\"The Confusion Matrix is: \")\n",
    "print(conf_mat)\n",
    "_,precision,recall = more_metrics(pd.DataFrame(conf_mat))\n",
    "print(\"The Precision & Recall is: \")\n",
    "df = pd.DataFrame(np.multiply(precision,100))\n",
    "df.columns = [\"Recall\"]\n",
    "df1 = pd.DataFrame(np.multiply(recall,100))\n",
    "df1.columns = [\"Precision\"]\n",
    "print(pd.concat([df,df1],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
