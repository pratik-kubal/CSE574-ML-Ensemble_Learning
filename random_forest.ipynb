{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import cross_validate,StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_data,test_target,classifier):\n",
    "    correct=0\n",
    "    conf_mat = confusion_matrix(test_target,classifier.predict(test_data))\n",
    "    for i in range(len(conf_mat)):\n",
    "        correct += conf_mat[i][i]\n",
    "    return correct/len(test_data),conf_mat\n",
    "\n",
    "def more_metrics(conf_mat):\n",
    "    true_positives = 0\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for i in range(len(conf_mat)):\n",
    "        true_positives += conf_mat.iloc[i,i]\n",
    "    conf_mat = np.matrix(conf_mat)\n",
    "    tp_fp = np.array(np.sum(conf_mat,axis=1)).ravel()\n",
    "    relevant_elements = np.array(np.sum(conf_mat,axis=0)).ravel()\n",
    "    for i in range(len(conf_mat)):\n",
    "        precision.append(conf_mat[i,i]/tp_fp[i])\n",
    "        recall.append(conf_mat[i,i]/relevant_elements[i])\n",
    "    return true_positives,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "train_data = training_data[0]\n",
    "train_target = training_data[1]\n",
    "val_data = validation_data[0]\n",
    "val_target = validation_data[1]\n",
    "test_target = test_data[1]\n",
    "test_data = test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''filename = '../mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "train_data = np.append(training_data[0],validation_data[0],axis=0)\n",
    "train_target = np.append(training_data[1],validation_data[1],axis=0)\n",
    "test_target = test_data[1]\n",
    "test_data = test_data[0]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "processed_train_data = scaler.transform(train_data)\n",
    "scaler.fit(val_data)\n",
    "processed_val_data = scaler.transform(val_data)\n",
    "scaler.fit(test_data)\n",
    "processed_test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseClassifier = RandomForestClassifier(n_estimators=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1500, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highVarClassifier = RandomForestClassifier(n_estimators=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2500, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib.dump(superhighVarClassifier,'./models/randomForestModel.joblib')\n",
    "#joblib.load('./models/randomForestModel.joblib') \n",
    "superhighVarClassifier = RandomForestClassifier(n_estimators=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = baseClassifier\n",
    "classifier.fit(processed_train_data, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Models on different HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Validation is: 0.8902\n",
      "The Confusion Matrix is: \n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  929    0   14    4    5    6   16    1   15    1\n",
      "1    0  903   95    7    6   10    9    1   32    1\n",
      "2    6    1  924   14    4    4    9   10   15    3\n",
      "3    7    2   38  931    1   14    1    3   29    4\n",
      "4    3    4   15    0  914    3    4    7    7   26\n",
      "5   19    0   19  110    6  700   11    3   39    8\n",
      "6    3    0   10    2   18    4  919    0   11    0\n",
      "7    4    6   16   23   29    6    0  903    9   94\n",
      "8    9    5   20   14    8   10    3    4  930    6\n",
      "9    4    0   10   17   36   10    1   18   16  849\n",
      "The Precision & Recall is: \n",
      "   Precision     Recall\n",
      "0  93.743693  94.410569\n",
      "1  84.868421  98.045603\n",
      "2  93.333333  79.586563\n",
      "3  90.388350  82.976827\n",
      "4  92.980671  88.997079\n",
      "5  76.502732  91.264668\n",
      "6  95.036194  94.450154\n",
      "7  82.844037  95.052632\n",
      "8  92.170466  84.315503\n",
      "9  88.345473  85.584677\n"
     ]
    }
   ],
   "source": [
    "acc,conf_mat = accuracy(processed_val_data,val_target,classifier)\n",
    "print(\"The Accuracy for Validation is: \"+str(acc))\n",
    "print(\"The Confusion Matrix is: \")\n",
    "print(pd.DataFrame(conf_mat))\n",
    "_,precision,recall = more_metrics(pd.DataFrame(conf_mat))\n",
    "print(\"The Precision & Recall is: \")\n",
    "df = pd.DataFrame(np.multiply(precision,100))\n",
    "df.columns = [\"Precision\"]\n",
    "df1 = pd.DataFrame(np.multiply(recall,100))\n",
    "df1.columns = [\"Recall\"]\n",
    "print(pd.concat([df,df1],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Process USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = '../USPSdata/Numerals'\n",
    "savedImg = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-np.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14825741287064353,\n",
       " array([[ 244,    4,  273,  428,    1,   23,   88,    0,  933,    6],\n",
       "        [  31,    1,  180,  690,    2,    7,    8,    0, 1077,    4],\n",
       "        [ 145,    4,  448,  440,    4,   31,   18,    0,  904,    5],\n",
       "        [  48,    0,  132,  639,    0,   19,    7,    0, 1154,    1],\n",
       "        [  63,    1,   88,  385,   10,   23,   10,    0, 1415,    5],\n",
       "        [  93,    3,  162,  434,    6,   67,   28,    0, 1206,    1],\n",
       "        [ 172,    1,  208,  432,   13,   78,  157,    1,  933,    5],\n",
       "        [  53,    7,  135,  604,    2,   23,   21,    0, 1154,    1],\n",
       "        [  70,    2,   92,  342,    8,   45,   48,    0, 1391,    2],\n",
       "        [  33,    4,  131,  579,    4,   18,    5,    2, 1216,    8]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(USPSMat)\n",
    "processed_USPSDat = scaler.transform(USPSMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Testing on MNIST is: 0.9284\n",
      "The Confusion Matrix is: \n",
      "[[ 970    0    1    1    0    3    2    2    1    0]\n",
      " [   0 1088    2   13    2   16    5    0    8    1]\n",
      " [  13    1  956    9    5    2    6   11   27    2]\n",
      " [   8    2   19  930    0   20    1    7   19    4]\n",
      " [   3    2    6    6  927    4    8    1    5   20]\n",
      " [  15    1    5   36    3  817    5    2    6    2]\n",
      " [  15    3    3    1    8   10  909    0    9    0]\n",
      " [   5    6   30   14   14    2    1  919   13   24]\n",
      " [   9    1   11   30    8   16    6    4  878   11]\n",
      " [   6    2    7   28   46    9    2    6   13  890]]\n",
      "The Precision & Recall is: \n",
      "   Precision     Recall\n",
      "0  98.979592  92.911877\n",
      "1  95.859031  98.372514\n",
      "2  92.635659  91.923077\n",
      "3  92.079208  87.078652\n",
      "4  94.399185  91.510365\n",
      "5  91.591928  90.878754\n",
      "6  94.885177  96.190476\n",
      "7  89.396887  96.533613\n",
      "8  90.143737  89.683350\n",
      "9  88.206145  93.291405\n"
     ]
    }
   ],
   "source": [
    "acc,conf_mat = accuracy(processed_test_data,test_target,classifier)\n",
    "print(\"The Accuracy for Testing on MNIST is: \"+str(acc))\n",
    "print(\"The Confusion Matrix is: \")\n",
    "print(conf_mat)\n",
    "_,precision,recall = more_metrics(pd.DataFrame(conf_mat))\n",
    "print(\"The Precision & Recall is: \")\n",
    "df = pd.DataFrame(np.multiply(precision,100))\n",
    "df.columns = [\"Precision\"]\n",
    "df1 = pd.DataFrame(np.multiply(recall,100))\n",
    "df1.columns = [\"Recall\"]\n",
    "print(pd.concat([df,df1],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Testing on USPS is: 0.120006000300015\n",
      "The Confusion Matrix is: \n",
      "[[ 126    0  493  161   63   28   95   13  936   85]\n",
      " [  15    0  246   96    1    9    5    2 1594   32]\n",
      " [  80    1  394  101   10   14   19    3 1360   17]\n",
      " [  66    0  263  343    3   23   15    0 1278    9]\n",
      " [  32    0  262  186   25   35   36    2 1373   49]\n",
      " [  83    0  411  166   27   51   47    0 1186   29]\n",
      " [ 214    0  361   88   78   27  117   11 1079   25]\n",
      " [  50    0  105  126   44    5   15    1 1635   19]\n",
      " [ 100    0  154  222   83   59   57    0 1298   27]\n",
      " [  59    2  206  245   18   19   14    0 1392   45]]\n",
      "The Precision & Recall is: \n",
      "   Precision     Recall\n",
      "0   6.300000  15.272727\n",
      "1   0.000000   0.000000\n",
      "2  19.709855  13.609672\n",
      "3  17.150000  19.780854\n",
      "4   1.250000   7.102273\n",
      "5   2.550000  18.888889\n",
      "6   5.850000  27.857143\n",
      "7   0.050000   3.125000\n",
      "8  64.900000   9.885005\n",
      "9   2.250000  13.353116\n"
     ]
    }
   ],
   "source": [
    "acc,conf_mat = accuracy(processed_USPSDat,USPSTar,classifier)\n",
    "print(\"The Accuracy for Testing on USPS is: \"+str(acc))\n",
    "print(\"The Confusion Matrix is: \")\n",
    "print(conf_mat)\n",
    "_,precision,recall = more_metrics(pd.DataFrame(conf_mat))\n",
    "print(\"The Precision & Recall is: \")\n",
    "df = pd.DataFrame(np.multiply(precision,100))\n",
    "df.columns = [\"Precision\"]\n",
    "df1 = pd.DataFrame(np.multiply(recall,100))\n",
    "df1.columns = [\"Recall\"]\n",
    "print(pd.concat([df,df1],axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
